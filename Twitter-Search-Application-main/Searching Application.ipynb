{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62115f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pymongo\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import mysql.connector as cnx\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9b4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mysql server\n",
    "mydb = cnx.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Adarsh20@\",\n",
    "  database=\"mydatabase\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7cff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to mongodb\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\") \n",
    "db = client[\"Tweets\"]\n",
    "tweets_collec = db[\"Tweets_Collection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad09098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    def __init__(self, max_size=15000, evict_strategy='least_accessed', checkpoint_interval=30, ttl=None):\n",
    "        self.max_size = max_size\n",
    "        self.evict_strategy = evict_strategy\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.ttl = ttl\n",
    "        self.cache = {}\n",
    "        self.access_count = {}\n",
    "        self.last_checkpoint = time.time()\n",
    "    \n",
    "        if os.path.exists('cache.checkpoint'):\n",
    "            self.load_from_checkpoint('cache.checkpoint')\n",
    "\n",
    "    def load_from_checkpoint(self, checkpoint_file):\n",
    "        with open(checkpoint_file, 'rb') as f:\n",
    "            self.cache, self.access_count = pickle.load(f)\n",
    "\n",
    "    def save_to_checkpoint(self, checkpoint_file):\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump((self.cache, self.access_count), f)\n",
    "            \n",
    "    def get(self, key):\n",
    "        \n",
    "        if key[0].isdigit() or key.startswith('#'):\n",
    "            if key not in self.cache:\n",
    "                return None\n",
    "            similar_keys = [key]\n",
    "            \n",
    "        else:\n",
    "            similar_keys = []\n",
    "            for k in self.cache:\n",
    "                if key in k:\n",
    "                    similar_keys.append(k)\n",
    "\n",
    "            if len(similar_keys) == 0:\n",
    "                return None\n",
    "        \n",
    "        if self.ttl is not None and (time.time() - self.cache[key]['timestamp']) > self.ttl:\n",
    "            del self.cache[key]\n",
    "            del self.access_count[key]\n",
    "            return None\n",
    "        \n",
    "        for i in similar_keys:\n",
    "            self.access_count[i] += 1\n",
    "            \n",
    "            if self.evict_strategy == 'least_accessed':\n",
    "                least_accessed_key = min(self.access_count, key=self.access_count.get)\n",
    "                if len(self.cache) > self.max_size and key != least_accessed_key:\n",
    "                    del self.cache[least_accessed_key]\n",
    "                    del self.access_count[least_accessed_key]\n",
    "                \n",
    "        return [self.cache[k]['value'] for k in similar_keys]\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if not key.startswith('#'):\n",
    "            key = key.lower()\n",
    "        self.cache[key] = {'value': value, 'timestamp': time.time()}\n",
    "        self.access_count[key] = 0\n",
    "        if len(self.cache) > self.max_size:\n",
    "            if self.evict_strategy == 'least_accessed':\n",
    "                least_accessed_key = min(self.access_count, key=self.access_count.get)\n",
    "                del self.cache[least_accessed_key]\n",
    "                del self.access_count[least_accessed_key]\n",
    "            elif self.evict_strategy == 'oldest':\n",
    "                oldest_key = min(self.cache, key=lambda k: self.cache[k]['timestamp'])\n",
    "                del self.cache[oldest_key]\n",
    "                del self.access_count[oldest_key]\n",
    "                \n",
    "        if (time.time() - self.last_checkpoint) > self.checkpoint_interval:\n",
    "            self.save_to_checkpoint('cache.checkpoint')\n",
    "            self.last_checkpoint = time.time()\n",
    "            \n",
    "    def print_cache(self):\n",
    "        print('Cache:')\n",
    "        for key, value in self.cache.items():\n",
    "            print(f\"{key}\")\n",
    "        used_space = len(self.cache)\n",
    "        remaining_space = self.max_size - used_space\n",
    "        print(f\"Cache size: {used_space}\")\n",
    "        print(f\"Remaining space: {remaining_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb306a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dd424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweet counte per each user\n",
    "def count_tweets_per_user():\n",
    "    tweet_counts = {}\n",
    "    cursor = tweets_collec.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$User_Id\", \"count\": {\"$sum\": 1}}}\n",
    "    ])\n",
    "    for user in cursor:\n",
    "        tweet_counts[user['_id']] = user['count']\n",
    "    return tweet_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d8282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results to a csv file to load it into mysql database\n",
    "def write_tweets_to_csv(filename, tweets_dict):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['User_ID', 'Tweets_Count'])\n",
    "        for user_id, count in tweets_dict.items():\n",
    "            writer.writerow([str(user_id), count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08478a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict = count_tweets_per_user()\n",
    "write_tweets_to_csv('tweets_counts.csv', tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93caba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the search term starts with '@'\n",
    "def UserSearch(search_term):\n",
    "    \n",
    "    if search_term.startswith('@'):\n",
    "    # remove the '@' symbol from the search term\n",
    "        search_term = search_term[1:]\n",
    "        \n",
    "        if cache.get(search_term):\n",
    "            print(\"getting\")\n",
    "            results = cache.get(search_term)\n",
    "            \n",
    "        else:\n",
    "            print(\"putting\")\n",
    "            # execute the query to search for user details based on username\n",
    "            query = \"\"\"\n",
    "                SELECT * FROM users \n",
    "                WHERE name LIKE %s \n",
    "                ORDER BY followers_count DESC, tweets_count DESC, verified DESC\n",
    "                LIMIT 5\n",
    "                \"\"\"\n",
    "            mycursor.execute(query, ('%' + search_term + '%',))\n",
    "            results = mycursor.fetchall()\n",
    "            for i in range(0,len(results)):\n",
    "                cache.put(results[i][1], results[i])\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d26bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tweets(user_id):\n",
    "    \n",
    "    if cache.get(user_id):\n",
    "        print(\"getting tweet\")\n",
    "        tweet_details = cache.get(user_id)\n",
    "    \n",
    "    else:\n",
    "        print(\"putting tweet\")\n",
    "        \n",
    "        user_tweets = list(tweets_collec.find({'User_Id': user_id}).sort([('created_at', -1)]).limit(3))\n",
    "        tweet_details = []\n",
    "        \n",
    "        for tweet in user_tweets:\n",
    "            tweet_details.append({\n",
    "                'created_at': tweet['created_at'],\n",
    "                'text': tweet['Text'],\n",
    "                'hashtags': tweet['Hashtag'],\n",
    "                'retweet_count': tweet['Retweet_Count'],\n",
    "                'likes_count': tweet['Likes_Count']\n",
    "            })\n",
    "        \n",
    "        cache.put(user_id, tweet_details)\n",
    "    return tweet_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00e085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserPrint(results):\n",
    "    for result in results:\n",
    "        user_id = result[0]\n",
    "        tweets_cache[user_id] = get_user_tweets(user_id)\n",
    "        if result[3]==1:\n",
    "            verified_status=\"‚úÖ\"\n",
    "        else:\n",
    "            verified_status=\"‚ùå\"\n",
    "            /\n",
    "        line1 = \"Name: {} | Verified: {}\".format(result[1], verified_status)\n",
    "        # format the remaining fields in another line\n",
    "        line2 = \"Followers: {} | Tweets: {}\".format(result[4], result[8])\n",
    "        line3 = \"Description : {}\".format(result[9])\n",
    "        line4=\"Location : {} | Creation Date:{}\".format(result[7],result[6])\n",
    "        \n",
    "        # print both lines\n",
    "        print(line1)\n",
    "        print(line2)\n",
    "        print(line3)\n",
    "        print(line4)\n",
    "        print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0abbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the search term: @sai\n",
      "getting\n",
      "getting tweet\n",
      "Name: Rajdeep Sardesai | Verified: ‚úÖ\n",
      "Followers: 8931083 | Tweets: 7\n",
      "Description : Citizen first. Only 'ism' is humanism. newsman, tv anchor, author, father, friend. New book: 2019: How Modi Won India. pre order here: http://bit.ly/HowModiWon\n",
      "Location : New Delhi | Creation Date:2009-07-13 06:14:44\n",
      "--------------------------------------------\n",
      "getting tweet\n",
      "Name: Muhammad Said Didu | Verified: ‚ùå\n",
      "Followers: 280708 | Tweets: 5\n",
      "Description : Katakan yang benar walau pahit!\n",
      "\n",
      "Gusur kebohongan dengan Akal Sehat\n",
      "Location : None | Creation Date:2019-04-16 03:17:01\n",
      "--------------------------------------------\n",
      "getting tweet\n",
      "Name: Umar Saif | Verified: ‚úÖ\n",
      "Followers: 133997 | Tweets: 2\n",
      "Description : CEO https://t.co/r5VNxYpRRI; Chief Digital Officer Jang/Geo; Chief Investment Officer Khudi Ventures; UNESCO Chair ICTD; MIT TR35; YGL; Sitara-i-Imtiaz; Former PITB, ITU\n",
      "Location : None | Creation Date:2009-06-25 19:41:31\n",
      "--------------------------------------------\n",
      "Load more results? (yes/no) y\n",
      "getting tweet\n",
      "Name: Said Taghmaoui | Verified: ‚úÖ\n",
      "Followers: 53423 | Tweets: 0\n",
      "Description : Said Taghmaoui was born July19th 1973 in 93 Seine-Saint-Denis France international actor has made films in Italy Germany USA and Morocco\n",
      "Location : None | Creation Date:2011-09-21 19:25:40\n",
      "--------------------------------------------\n",
      "getting tweet\n",
      "Name: Firza Husain | Verified: ‚ùå\n",
      "Followers: 35026 | Tweets: 4\n",
      "Description : Korban kemunafikan seorang tokoh üò¢üò¢üò¢\n",
      "Location : Jakarta Raya | Creation Date:2017-01-05 00:37:57\n",
      "--------------------------------------------\n",
      "Enter the number of the user whose tweets you want to see: 2\n",
      "Tweets of Muhammad Said Didu:\n",
      "[{'created_at': '2020-04-25 14:44:43', 'text': 'RT @detikcom: Bocah 8 tahun yang meninggal diketahui reaktif atau positif Corona namun orang tua anak tidak jujur soal riwayat perjalanan k‚Ä¶', 'hashtags': [], 'retweet_count': 0, 'likes_count': 0}, {'created_at': '2020-04-24 21:30:09', 'text': 'Sepertinya anda perlu banyak baca. \\nNih 12 rekomendasi Tim Reformasi Migas yg dipimpin pak @FaisalBasri‚Ä¶ https://t.co/bK8i6SStEF', 'hashtags': [], 'retweet_count': 21, 'likes_count': 1202}, {'created_at': '2020-04-22 12:29:58', 'text': 'Ya Allah hanya kepadamu tempat kami berlindung', 'hashtags': [], 'retweet_count': 1, 'likes_count': 659}]\n",
      "Time for getting user info:  0.00035089999983028974\n",
      "Time for getting tweets info:  0.00037650000012945384\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter the search term: \")\n",
    "\n",
    "start_sql = time.perf_counter()\n",
    "results=UserSearch(search_term)\n",
    "end_sql = time.perf_counter()\n",
    "\n",
    "sql_time = end_sql - start_sql\n",
    "\n",
    "\n",
    "start_mongo = time.perf_counter()\n",
    "tweets_cache = {}\n",
    "UserPrint(results[:3])\n",
    "end_mongo = time.perf_counter()\n",
    "mongo_time = end_mongo - start_mongo\n",
    "\n",
    "    # check if there are more results\n",
    "if len(results) > 3:\n",
    "        # prompt the user to load more results\n",
    "    load_more = input(\"Load more results? (yes/no) \")\n",
    "    if load_more.lower().startswith('y'):\n",
    "        UserPrint(results[3:5])\n",
    "user_choice = int(input(\"Enter the number of the user whose tweets you want to see: \"))\n",
    "\n",
    "# Get the user_id of the selected user\n",
    "user_id = results[user_choice-1][0]\n",
    "\n",
    "# Display the tweets of the selected user\n",
    "\n",
    "if user_id in tweets_cache:\n",
    "    print(f\"Tweets of {results[user_choice-1][1]}:\")\n",
    "    for tweet in tweets_cache[user_id]:\n",
    "        print(tweet)\n",
    "else:\n",
    "    print(\"No tweets found for the selected user.\")\n",
    "    \n",
    "print(\"Time for getting user info: \", sql_time)\n",
    "print(\"Time for getting tweets info: \", mongo_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search by hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bdd7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_hashtags(search_string, limit=5):\n",
    "    \n",
    "    if search_string.startswith('#'):\n",
    "        search_string = search_string[1:]\n",
    "        \n",
    "        hashtags = tweets_collec.aggregate([\n",
    "        { \"$match\": { \"Hashtag\": { \"$regex\": search_string, \"$options\": \"i\" } } },\n",
    "        { \"$unwind\": \"$Hashtag\" },\n",
    "        { \"$group\": { \"_id\": \"$Hashtag\", \"count\": { \"$sum\": 1 } } },\n",
    "        { \"$sort\": { \"count\": -1 } },\n",
    "        { \"$limit\": limit }\n",
    "        ])\n",
    "        \n",
    "        hashtag_dict = {}\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_dict[hashtag['_id']] = hashtag['count']\n",
    "            \n",
    "        return hashtag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81771c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_of_hashtag(hashtag):\n",
    "    \n",
    "    if cache.get('#' + hashtag):\n",
    "        tweets = cache.get(hashtag)[0]\n",
    "    else:\n",
    "        tweets = list(tweets_collec.find({'Hashtag': hashtag}).sort('created_at', -1).limit(3))\n",
    "        cache.put('#' + hashtag, tweets)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f65463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hashtag_print(hashtags):\n",
    "    print()\n",
    "    print(\"Top 5 hashtags matching the search string: \")\n",
    "    print()\n",
    "    for k,v in hashtags.items():\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"Hashtag: {} | Tweets Count: {}\\n\".format(k, v))\n",
    "    \n",
    "    for hashtag in hashtags.keys():\n",
    "        temp_hashtag[hashtag] = tweets_of_hashtag(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a4ebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the hashtag: #bjp\n",
      "\n",
      "Top 5 hashtags matching the search string: \n",
      "\n",
      "\n",
      "Enter the hashtag whose tweets you want to see: 2\n",
      "No tweets found for the selected hashtag.\n",
      "Time for getting tweets info:  0.0001971000001503853\n"
     ]
    }
   ],
   "source": [
    "# level 1 display\n",
    "search_hashtag = input(\"Enter the hashtag: \")\n",
    "hashtags = get_top_hashtags(search_hashtag)\n",
    "\n",
    "temp_hashtag = {}\n",
    "\n",
    "start_hashtag = time.perf_counter()\n",
    "Hashtag_print(hashtags)\n",
    "end_hashtag = time.perf_counter()\n",
    "hashtag_time = end_hashtag - start_hashtag\n",
    "\n",
    "\n",
    "print()\n",
    "hashtag_choice = input(\"Enter the hashtag whose tweets you want to see: \")\n",
    "\n",
    "if hashtag_choice in temp_hashtag:\n",
    "    print()\n",
    "    print(f\"Tweets of {hashtag_choice}:\")\n",
    "    for tweet in temp_hashtag[hashtag_choice]:\n",
    "        line_1 = \"User: {} | Retweets: {} | Likes: {} | Created at: {}\".format(tweet['User_Name'], tweet['Retweet_Count'], tweet['Likes_Count'], tweet['created_at'])\n",
    "        line_2 = \"Text: {}\".format(tweet['Text'])\n",
    "        \n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        print()\n",
    "        print(line_1)\n",
    "        print(line_2)\n",
    "        print(\"Hashtags: {}\".format(tweet['Hashtag']))\n",
    "else:\n",
    "    print(\"No tweets found for the selected hashtag.\")\n",
    "    \n",
    "print(\"Time for getting tweets info: \", hashtag_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc7f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text_text'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_collec.create_index([(\"Text\", \"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff23355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(search_string):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    search_words = search_string.split()\n",
    "    if len(set(search_words) - stop_words) == 0:\n",
    "        return \"Error\"\n",
    "    \n",
    "    search_string = '\"' + search_string + '\"'\n",
    "    # Search for tweets matching the search string\n",
    "    query = {'$text': {'$search': search_string}}\n",
    "    projection = {'_id': 0, 'Text': 1, 'ext': 1, 'created_at': 1, 'Retweet_Count': 1, 'favorite_count': 1, 'Hashtags': 1}\n",
    "    matching_tweets = list(tweets_collec.find(query).sort([('retweeted_status', 1), ('created_at', -1)]).limit(5))\n",
    "\n",
    "\n",
    "    # Print number of matching tweets and return the results\n",
    "    print(f\"Number of matching tweets: {len(matching_tweets)}\")\n",
    "    return matching_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88b46b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching tweets: 0\n",
      "Time for getting tweets info for a string:  0.01630150000028152\n"
     ]
    }
   ],
   "source": [
    "start_string = time.perf_counter()\n",
    "results = search_tweets('death on')\n",
    "end_string = time.perf_counter()\n",
    "string_time = end_string - start_string\n",
    "\n",
    "\n",
    "\n",
    "if (results==\"Error\"):\n",
    "    print(\"Error: Please provide a non stop word\")\n",
    "else:\n",
    "    for tweet in results:\n",
    "        print(tweet)\n",
    "        print(\"------------------\")\n",
    "\n",
    "print(\"Time for getting tweets info for a string: \", string_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6733d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('813286',\n",
       "  'Barack Obama',\n",
       "  'BarackObama',\n",
       "  1,\n",
       "  116518121,\n",
       "  607194,\n",
       "  'Washington, DC',\n",
       "  0,\n",
       "  'Dad, husband, President, citizen.'),\n",
       " ('25073877',\n",
       "  'Donald J. Trump',\n",
       "  'realDonaldTrump',\n",
       "  1,\n",
       "  78467254,\n",
       "  46,\n",
       "  'Washington, DC',\n",
       "  0,\n",
       "  '45th President of the United States of Americaüá∫üá∏'),\n",
       " ('428333',\n",
       "  'CNN Breaking News',\n",
       "  'cnnbrk',\n",
       "  1,\n",
       "  57529057,\n",
       "  120,\n",
       "  'Everywhere',\n",
       "  0,\n",
       "  'Breaking news from CNN Digital. Now 56M strong. Check @cnn for all things CNN, breaking and more. Download the app for custom alerts: http://cnn.com/apps'),\n",
       " ('18839785',\n",
       "  'Narendra Modi',\n",
       "  'narendramodi',\n",
       "  1,\n",
       "  55781248,\n",
       "  2364,\n",
       "  'India',\n",
       "  0,\n",
       "  'Prime Minister of India'),\n",
       " ('44409004',\n",
       "  'Shakira',\n",
       "  'shakira',\n",
       "  1,\n",
       "  52250613,\n",
       "  212,\n",
       "  'Barranquilla',\n",
       "  0,\n",
       "  'üéôME GUSTA Shakira & Anuel AA Nuevo Sencillo / New Single'),\n",
       " ('759251',\n",
       "  'CNN',\n",
       "  'CNN',\n",
       "  1,\n",
       "  47565193,\n",
       "  1106,\n",
       "  None,\n",
       "  0,\n",
       "  'It‚Äôs our job to #GoThere & tell the most difficult stories. Join us! For more breaking news updates follow @CNNBRK  & Download our app http://cnn.com/apps'),\n",
       " ('807095',\n",
       "  'The New York Times',\n",
       "  'nytimes',\n",
       "  1,\n",
       "  46361159,\n",
       "  904,\n",
       "  'New York City',\n",
       "  0,\n",
       "  'News tips? Share them here: http://nyti.ms/2FVHq9v'),\n",
       " ('5402612',\n",
       "  'BBC Breaking News',\n",
       "  'BBCBreaking',\n",
       "  1,\n",
       "  43014510,\n",
       "  3,\n",
       "  'London, UK',\n",
       "  0,\n",
       "  'Breaking news alerts and updates from the BBC. For news, features, analysis follow @BBCWorld (international) or @BBCNews (UK). Latest sport news @BBCSport.'),\n",
       " ('145125358',\n",
       "  'Amitabh Bachchan',\n",
       "  'SrBachchan',\n",
       "  1,\n",
       "  41596464,\n",
       "  1833,\n",
       "  'Mumbai, India',\n",
       "  0,\n",
       "  '\"‡§§‡•Å‡§Æ‡§®‡•á ‡§π‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§ú ‡§™‡•Ç‡§ú ‡§ï‡§∞ ‡§™‡§§‡•ç‡§•‡§∞ ‡§ï‡§∞ ‡§°‡§æ‡§≤‡§æ ; ‡§µ‡•á ‡§ú‡•ã ‡§π‡§Æ‡§™‡§∞ ‡§ú‡•Å‡§Æ‡§≤‡•á ‡§ï‡§∏‡§§‡•á ‡§π‡•à‡§Ç ‡§π‡§Æ‡•á‡§Ç ‡§ú‡§º‡§ø‡§Ç‡§¶‡§æ ‡§§‡•ã ‡§∏‡§Æ‡§ù‡§§‡•á ‡§π‡•à‡§Ç \"~  ‡§π‡§∞‡§ø‡§µ‡§Ç‡§∂ ‡§∞‡§æ‡§Ø  ‡§¨‡§ö‡•ç‡§ö‡§®'),\n",
       " ('132385468',\n",
       "  'Salman Khan',\n",
       "  'BeingSalmanKhan',\n",
       "  1,\n",
       "  40094611,\n",
       "  26,\n",
       "  'MUMBAI',\n",
       "  0,\n",
       "  'Film actor, artist, painter, humanitarian')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Top 10 users with most followers, tweets\n",
    "query = \"\"\"select id,name,screen_name,verified,followers_count,friends_count,location,tweets_count,Description from mydatabase.users \n",
    " order by followers_count DESC,tweets_count DESC \n",
    " limit 10\"\"\"\n",
    "\n",
    "mycursor.execute(query)\n",
    "top_10_users = mycursor.fetchall()\n",
    "top_10_users\n",
    "#cache.put('top_10_users', top_10_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de57ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_users = cache.get('top_10_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f215f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Top 10 Tweets with most a composite score of Retweets*0.6 + Likes*0.4\n",
    "# def get_top_tweets():\n",
    "#     tweets = tweets_collec.find().sort([(\"Retweet_Count\", -1), (\"Likes_Count\", -1)]).limit(10)\n",
    "#     top_tweets = []\n",
    "#     for tweet in tweets:\n",
    "#         score = tweet['Retweet_Count'] * 0.6 + tweet['Likes_Count'] * 0.4\n",
    "#         tweet['score'] = score\n",
    "#         top_tweets.append(tweet)\n",
    "#     top_tweets = sorted(top_tweets, key=lambda x: x['score'], reverse=True)\n",
    "#     return top_tweets\n",
    "\n",
    "# top_10_tweets = get_top_tweets()\n",
    "# cache.put('top_10_tweets', top_10_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad4761f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_tweets = cache.get('top_10_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "119c092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Top 10 hashtags with are present in most tweets\n",
    "# def get_top_hashtags(limit=10):\n",
    "#     pipeline = [\n",
    "#         {\"$unwind\": \"$Hashtag\"},\n",
    "#         {\"$group\": {\"_id\": \"$Hashtag\", \"count\": {\"$sum\": 1}}},\n",
    "#         {\"$sort\": {\"count\": -1}},\n",
    "#         {\"$limit\": limit}\n",
    "#     ]\n",
    "#     top_hashtags = list(tweets_collec.aggregate(pipeline))\n",
    "#     top_hashtags_dict = {}\n",
    "#     for hashtag in top_hashtags:\n",
    "#         top_hashtags_dict[hashtag['_id']] = hashtag['count']\n",
    "#     return top_hashtags_dict\n",
    "\n",
    "# top_10_hashtags = get_top_hashtags()\n",
    "# cache.put('top_10_hashtags', top_10_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0e16d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_hashtags = cache.get('top_10_hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1adc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588a1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
